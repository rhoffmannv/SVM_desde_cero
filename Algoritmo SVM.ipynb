{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7502f4",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a456e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fb66f",
   "metadata": {},
   "source": [
    "## Definir clase para algoritmo SVM\n",
    "\n",
    "### Constructor\n",
    "\n",
    "Se definen las variables relevantes para el algoritmo:\n",
    "- *learning rate*: Par√°metro que define el tama√±o de las correcciones de los pesos en entrenamiento.\n",
    "- *lambda param*: Par√°metro que define la importancia relativa entre minimizar los pesos y reducir el n√∫mero de instancias mal clasificadas y penalizadas.\n",
    "- *n_iters*: N√∫mero de iteraciones para el entrenamiento.\n",
    "- *w*: Pesos del modelo, que definen el hiperplano para realizar la clasificaci√≥n.\n",
    "- *b*: Constante del modelo que define donde el hiperplano cruza el origen.\n",
    "\n",
    "### Fit\n",
    "\n",
    "Funci√≥n para ajustar los pesos del modelo, que definen el hiperplano para separar los datos y realizar la clasificaci√≥n.\n",
    "Se usa el m√©todo del gradiente descendiente para el ajuste de pesos.\n",
    "\n",
    "- Se buscan los pesos *w* tal que se cumpla:\n",
    "\n",
    "$$f(x_i) =\n",
    "    \\begin{cases}\n",
    "    w\\cdot x_i + b \\ge 0 & si \\space y_i = +1 & \\\\\n",
    "    w\\cdot x_i + b < 0 & si \\space y_i = -1\n",
    "    \\end{cases}$$\n",
    "    \n",
    "\n",
    "- Lo que se puede resumir en la ecuaci√≥n:\n",
    "\n",
    "$$  y_i \\cdot h(x_i) = y_i(w\\cdot x_i+b) \\ge 1$$\n",
    "\n",
    "- Donde\n",
    "\n",
    "$$\\space h(x_i) = w\\cdot x_i + b$$\n",
    "\n",
    "- Se quiere minimizar los pesos para reducir la distancia entre los *vectores de soporte*, lo que se describe como:\n",
    "\n",
    "$$ l(w)= \\lambda\\|w\\|^2 $$\n",
    "\n",
    "\n",
    "- A la vez, se debe penalizar a las predicciones equivocadas:\n",
    "\n",
    "$$l_i =\n",
    "    \\begin{cases}\n",
    "    0 & si \\space y_i \\cdot h(x_i) \\ge 1 & \\\\\n",
    "    1 - y_i \\cdot f(x_i) & si \\, no\n",
    "    \\end{cases}$$\n",
    "\n",
    "- Juntando ambas condiciones, se busca minimizar la funci√≥n de costo:\n",
    "\n",
    "$$J_i =\n",
    "    \\begin{cases}\n",
    "    \\lambda \\|w\\|^2 & si \\space y_i \\cdot h(x_i) \\ge 1 & \\\\\n",
    "    \\lambda \\|w\\|^2 + 1-y_i(w\\cdot x_i - b) & si \\, no\n",
    "    \\end{cases}$$\n",
    "    \n",
    "- Calculando la derivada parcial con respecto a los pesos (para usar el algoritmo de gradiente descendiente) se tiene:\n",
    "\n",
    "$$\\frac{\\partial J_i}{\\partial w_k} =\n",
    "    \\begin{cases}\n",
    "    2 \\lambda w_k & si \\space y_i \\cdot h(x_i) \\ge 1 & \\\\\n",
    "    2 \\lambda w_k -y_i\\cdot x_{ik} & si \\, no\n",
    "    \\end{cases}$$\n",
    "    \n",
    "\n",
    "### Predict\n",
    "\n",
    "Funci√≥n para predecir clase del dato de entrada.\n",
    "\n",
    "- Para obtener la predicci√≥n del modelo sobre una instancia $x_i$ basta calcular:\n",
    "\n",
    "$$h(x_i) = w\\cdot x_i + b$$\n",
    "\n",
    "- Y la predicci√≥n del modelo es:\n",
    "\n",
    "$$y_i =\n",
    "    \\begin{cases}\n",
    "    1 & si \\space h(x_i) \\ge 0 & \\\\\n",
    "    0 & si \\space h(x_i) < 0\n",
    "    \\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c017026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, lambda_param=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Pasar la etiquetas de 0 y 1 a las etiquetas -1 y 1\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "\n",
    "        # Inicializar pesos\n",
    "        self.w = np.random.random((n_features))\n",
    "        self.b = 0\n",
    "\n",
    "        # Por cada iteraci√≥n de entrenamiento\n",
    "        for _ in range(self.n_iters):\n",
    "            # Por cada datapoint de entrenamiento\n",
    "            for idx, x_i in enumerate(X):\n",
    "                # Verificar la condici√≥n ùë¶ ‚ãÖ ‚Ñé(ùë•) ‚â• 1\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    # Usar el gradiente descendiente 2ùúÜùë§\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    # Usar el gradiente descendiente 2ùúÜùë§ ‚àí ùë¶ ‚ãÖ ùë•\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calcular ‚Ñé(ùë•) = ùë§ ‚ãÖ ùë• - ùëè, \n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        # Devolver 1 si ‚Ñé(ùë•) > 0 y devolver 0 si ‚Ñé(ùë•) < 0\n",
    "        return (approx >= 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01650789",
   "metadata": {},
   "source": [
    "## An√°lisis de resultados\n",
    "\n",
    "### C√°lculo de *accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return str(100*accuracy)[0:5] + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbfe64",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de resultados\n",
    "\n",
    "- Se grafica la intersecci√≥n del hiperplano para la clasificaci√≥n.\n",
    "- Se grafican los *vectores de soporte*.\n",
    "- Se grafican los *datapoints*, coloreandolos seg√∫n su etiqueta real.\n",
    "\n",
    "> Notar que se asume que los datos tienen dos dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_svm(X, y, w, b, title, x_label, y_label, name):\n",
    "    def get_hyperplane_value(x, w, b, offset):\n",
    "        return (-w[0] * x + b + offset) / w[1]\n",
    "\n",
    "    fig = plt.figure()    \n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # Graficar datapoints\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker=\"o\", c=y, cmap=plt.cm.coolwarm)\n",
    "    \n",
    "    # Metadata gr√°fico\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    x0_1 = np.amin(X[:, 0])\n",
    "    x0_2 = np.amax(X[:, 0])\n",
    "\n",
    "    # Intersecci√≥n del hiperplano\n",
    "    x1_1 = get_hyperplane_value(x0_1, w, b, 0)\n",
    "    x1_2 = get_hyperplane_value(x0_2, w, b, 0)\n",
    "\n",
    "    # L√≠nea donde funci√≥n del hiperplano es igual a -1 (vector de soporte)\n",
    "    x1_1_m = get_hyperplane_value(x0_1, w, b, -1)\n",
    "    x1_2_m = get_hyperplane_value(x0_2, w, b, -1)\n",
    "\n",
    "    # L√≠nea donde funci√≥n del hiperplano es igual a +1 (vector de soporte)\n",
    "    x1_1_p = get_hyperplane_value(x0_1, w, b, 1)\n",
    "    x1_2_p = get_hyperplane_value(x0_2, w, b, 1)\n",
    "\n",
    "    #Graficar linea de intersecci√≥n y vectores de soporte\n",
    "    ax.plot([x0_1, x0_2], [x1_1, x1_2], \"y--\")\n",
    "    ax.plot([x0_1, x0_2], [x1_1_m, x1_2_m], \"k\")\n",
    "    ax.plot([x0_1, x0_2], [x1_1_p, x1_2_p], \"k\")\n",
    "\n",
    "    x1_min = np.amin(X[:, 1])\n",
    "    x1_max = np.amax(X[:, 1])\n",
    "    ax.set_ylim([x1_min - 3, x1_max + 3])\n",
    "    \n",
    "    plt.savefig(\"images/\" + name + \".svg\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
